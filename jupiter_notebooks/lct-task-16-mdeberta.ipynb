{"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8697510,"sourceType":"datasetVersion","datasetId":5082283}],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2024-06-15T09:33:09.121325Z","iopub.execute_input":"2024-06-15T09:33:09.121688Z","iopub.status.idle":"2024-06-15T09:33:10.136930Z","shell.execute_reply.started":"2024-06-15T09:33:09.121662Z","shell.execute_reply":"2024-06-15T09:33:10.135804Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/train_data_-400.csv\n/kaggle/input/train_extend_5.csv\n/kaggle/input/train_test_extend_7.csv\n/kaggle/input/train_merged.csv\n/kaggle/input/train_chunks_512.csv\n/kaggle/input/train_test_extend_3.csv\n/kaggle/input/train_extend_7.csv\n/kaggle/input/test_extend_7.csv\n/kaggle/input/test_extend_5.csv\n/kaggle/input/test_extend.csv\n/kaggle/input/test_extend_6.csv\n/kaggle/input/train_extend.csv\n/kaggle/input/test_extend_3.csv\n/kaggle/input/train_merged_-400.csv\n/kaggle/input/train_Collection5.json\n/kaggle/input/test_extend_2.csv\n/kaggle/input/train.json\n/kaggle/input/train_extend_2.csv\n/kaggle/input/train_extend_3.csv\n/kaggle/input/train_test_extend_5.csv\n/kaggle/input/train_test_extend_4.csv\n/kaggle/input/train_test_extend_2.csv\n/kaggle/input/train_test_extend_8.csv\n/kaggle/input/train_data.csv\n/kaggle/input/test_extend_8.csv\n/kaggle/input/train_test_extend_6.csv\n/kaggle/input/train_extend_6.csv\n/kaggle/input/test_extend_4.csv\n/kaggle/input/train_extend_4.csv\n/kaggle/input/train_extend_8.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install seqeval\n# !pip install wandb --upgrade","metadata":{"execution":{"iopub.status.busy":"2024-06-15T09:33:10.138966Z","iopub.execute_input":"2024-06-15T09:33:10.139455Z","iopub.status.idle":"2024-06-15T09:33:26.828498Z","shell.execute_reply.started":"2024-06-15T09:33:10.139419Z","shell.execute_reply":"2024-06-15T09:33:26.827498Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting seqeval\n  Downloading seqeval-1.2.2.tar.gz (43 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /opt/conda/lib/python3.10/site-packages (from seqeval) (1.26.4)\nRequirement already satisfied: scikit-learn>=0.21.3 in /opt/conda/lib/python3.10/site-packages (from seqeval) (1.2.2)\nRequirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.21.3->seqeval) (1.11.4)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.21.3->seqeval) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.21.3->seqeval) (3.2.0)\nBuilding wheels for collected packages: seqeval\n  Building wheel for seqeval (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16162 sha256=22c514c6b15883475b7554bb645a714858f14fc810b54a141d8ed072653bccc4\n  Stored in directory: /root/.cache/pip/wheels/1a/67/4a/ad4082dd7dfc30f2abfe4d80a2ed5926a506eb8a972b4767fa\nSuccessfully built seqeval\nInstalling collected packages: seqeval\nSuccessfully installed seqeval-1.2.2\n","output_type":"stream"}]},{"cell_type":"code","source":"%matplotlib inline\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport ast\nfrom sklearn.metrics import f1_score, matthews_corrcoef\nfrom IPython.display import clear_output\nfrom nltk import pos_tag\nfrom tqdm import tqdm\nimport pandas as pd\nfrom sklearn.model_selection import KFold, StratifiedKFold\nimport os\nfrom IPython.display import clear_output\nimport gc\nimport joblib\n\nimport warnings\nwarnings.simplefilter(action = 'ignore', category = FutureWarning)\nwarnings.simplefilter(action = 'ignore', category = DeprecationWarning)\nwarnings.simplefilter(action = 'ignore', category = UserWarning)\nwarnings.simplefilter(action = 'ignore', category = RuntimeWarning)\nwarnings.filterwarnings(\"ignore\", message = \"numpy.dtype size changed\")\nwarnings.filterwarnings(\"ignore\", message = \"numpy.ufunc size changed\")\npd.options.mode.chained_assignment = None\n\nfrom warnings import simplefilter\nsimplefilter(action = \"ignore\", category = pd.errors.PerformanceWarning)\n\nimport torch\nimport transformers\n\nfrom torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\nfrom transformers import BertTokenizer, BertConfig, BertForTokenClassification\n\nfrom transformers import DebertaV2Tokenizer, DebertaV2ForTokenClassification\n\nfrom keras.utils import pad_sequences\nfrom sklearn.model_selection import train_test_split\n\nfrom transformers import AdamW, get_linear_schedule_with_warmup\n\nfrom seqeval.metrics import accuracy_score\nfrom sklearn.metrics import f1_score\nfrom tqdm import tqdm, trange\n\ntry:\n    %load_ext autotime\nexcept:\n    pass \n\nclear_output(wait = False)\n\nfrom pathlib import Path\nPath(\"./models/\").mkdir(parents = True, exist_ok = True)\nPath(\"./val/\").mkdir(parents = True, exist_ok = True)\nPath(\"./results/checkpoint-last\").mkdir(parents=True, exist_ok=True)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nn_gpu = torch.cuda.device_count()\nprint(device, n_gpu)\n\n# bert_name = \"Babelscape/wikineural-multilingual-ner\"\n# bert_name = \"sberbank-ai/ruBert-base\"\n# bert_name = 'bert-base-cased'\nbert_name = \"microsoft/mdeberta-v3-base\"\n\nMAX_LEN = 512\nOVERLAP = 0.2","metadata":{"execution":{"iopub.status.busy":"2024-06-15T09:33:26.829837Z","iopub.execute_input":"2024-06-15T09:33:26.830146Z","iopub.status.idle":"2024-06-15T09:33:45.168969Z","shell.execute_reply.started":"2024-06-15T09:33:26.830116Z","shell.execute_reply":"2024-06-15T09:33:45.168037Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"cuda 1\n","output_type":"stream"}]},{"cell_type":"code","source":"train_version = 8\n\n# Чтение файла train_extend.csv в датафрейм\n# df = pd.read_csv(f'/kaggle/input/train_extend_{train_version}.csv', sep=',')\ndf = pd.read_csv(f'/kaggle/input/train_test_extend_{train_version}.csv', sep=',')\n# Преобразование значения в поле 'target_labels_positions' в словарь с помощью модуля ast\ndf['target_labels_positions'] = df['target_labels_positions'].map(ast.literal_eval)\n\ntarget_labels = ['B-value', 'I-value', 'B-discount']\n\ndf","metadata":{"execution":{"iopub.status.busy":"2024-06-15T09:33:45.171243Z","iopub.execute_input":"2024-06-15T09:33:45.171795Z","iopub.status.idle":"2024-06-15T09:33:45.901045Z","shell.execute_reply.started":"2024-06-15T09:33:45.171769Z","shell.execute_reply":"2024-06-15T09:33:45.900079Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"                                         processed_text  \\\n0     аа союзная тридцать пять дробь один лариса сое...   \n1     аа приложение мне показывает к оплате у меня п...   \n2     да лисное по призрак лишнее ну почему иду пять...   \n3     а что добрый день NAME у меня пришел какой то ...   \n4     у меня западный с утра да да еще да да самый в...   \n...                                                 ...   \n7895  самостоятельно угроза клиент хочет узнать о во...   \n7896  сверкающий покидать жестокий единый клиент инт...   \n7897  бочок боец кидать через изображать клиент инте...   \n7898  затянуться возмутиться один клиент хочет узнат...   \n7899  беспомощный бегать горький госпожа инвалид кор...   \n\n                                target_labels_positions  synthetic  row_label  \n0                                                    {}          0          0  \n1                                                    {}          0          0  \n2     {'B-discount': [138, 212], 'B-value': [139], '...          0          2  \n3                                  {'B-discount': [12]}          0          1  \n4                                                    {}          0          0  \n...                                                 ...        ...        ...  \n7895  {'B-discount': [26], 'B-value': [29], 'I-value...          1          6  \n7896  {'B-discount': [146, 298], 'B-value': [147, 29...          1          6  \n7897  {'B-discount': [168], 'B-value': [161], 'I-val...          1          6  \n7898  {'B-discount': [169, 349], 'B-value': [164, 34...          1          6  \n7899  {'B-discount': [95, 169], 'B-value': [98, 171]...          1          6  \n\n[7900 rows x 4 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>processed_text</th>\n      <th>target_labels_positions</th>\n      <th>synthetic</th>\n      <th>row_label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>аа союзная тридцать пять дробь один лариса сое...</td>\n      <td>{}</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>аа приложение мне показывает к оплате у меня п...</td>\n      <td>{}</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>да лисное по призрак лишнее ну почему иду пять...</td>\n      <td>{'B-discount': [138, 212], 'B-value': [139], '...</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>а что добрый день NAME у меня пришел какой то ...</td>\n      <td>{'B-discount': [12]}</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>у меня западный с утра да да еще да да самый в...</td>\n      <td>{}</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>7895</th>\n      <td>самостоятельно угроза клиент хочет узнать о во...</td>\n      <td>{'B-discount': [26], 'B-value': [29], 'I-value...</td>\n      <td>1</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>7896</th>\n      <td>сверкающий покидать жестокий единый клиент инт...</td>\n      <td>{'B-discount': [146, 298], 'B-value': [147, 29...</td>\n      <td>1</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>7897</th>\n      <td>бочок боец кидать через изображать клиент инте...</td>\n      <td>{'B-discount': [168], 'B-value': [161], 'I-val...</td>\n      <td>1</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>7898</th>\n      <td>затянуться возмутиться один клиент хочет узнат...</td>\n      <td>{'B-discount': [169, 349], 'B-value': [164, 34...</td>\n      <td>1</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>7899</th>\n      <td>беспомощный бегать горький госпожа инвалид кор...</td>\n      <td>{'B-discount': [95, 169], 'B-value': [98, 171]...</td>\n      <td>1</td>\n      <td>6</td>\n    </tr>\n  </tbody>\n</table>\n<p>7900 rows × 4 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"sentences, labels, row_labels = [], [], []\n\nfor i, row in tqdm(df.iterrows(), total=len(df)):\n    words = row['processed_text'].split()\n    label_positions = row['target_labels_positions']\n    word_labels = ['O'] * len(words)\n\n    for label, positions in label_positions.items():\n        for pos in positions:\n            if 0 <= pos < len(words):\n                word_labels[pos] = label\n\n    sentences.append(words)\n    labels.append(word_labels)\n    row_labels.append(row['row_label'])","metadata":{"execution":{"iopub.status.busy":"2024-06-15T09:33:45.902301Z","iopub.execute_input":"2024-06-15T09:33:45.902658Z","iopub.status.idle":"2024-06-15T09:33:46.759804Z","shell.execute_reply.started":"2024-06-15T09:33:45.902624Z","shell.execute_reply":"2024-06-15T09:33:46.758847Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"100%|██████████| 7900/7900 [00:00<00:00, 9332.82it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"print(sentences[2])","metadata":{"execution":{"iopub.status.busy":"2024-06-15T09:33:46.761117Z","iopub.execute_input":"2024-06-15T09:33:46.761749Z","iopub.status.idle":"2024-06-15T09:33:46.766307Z","shell.execute_reply.started":"2024-06-15T09:33:46.761714Z","shell.execute_reply":"2024-06-15T09:33:46.765381Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"['да', 'лисное', 'по', 'призрак', 'лишнее', 'ну', 'почему', 'иду', 'пять', 'двух', 'полностью', 'последнего', 'да', 'да', 'да', 'и', 'там', 'есть', 'данные', 'надо', 'чтобы', 'стандартная', 'двух', 'что', 'была', 'пятьдесят', 'пятьдесят', 'десять', 'миллионов', 'три', 'а', 'первоначальный', 'вздох', 'сколько', 'вас', 'а', 'еще', 'какие', 'то', 'фиджи', 'приедем', 'там', 'сейчас', 'менеджера', 'да', 'вам', 'я', 'такая', 'там', 'проценты', 'а', 'если', 'не', 'столько', 'да', 'хорошо', 'конечно', 'и', 'это', 'заработал', 'хорошо', 'а', 'инвестое', 'отправьте', 'пожалуйстаздравствуйте', 'меня', 'зовут', 'на', 'менеджере', 'дело', 'продаж', 'группы', 'самолет', 'вы', 'рассматриваете', 'какой', 'то', 'определенный', 'комплекс', 'для', 'себя', 'что', 'хотели', 'просмотреть', 'сколько', 'комнат', 'двух', 'комнатная', 'квартира', 'так', 'давайте', 'посмотрим', 'я', 'вижу', 'вы', 'интересовались', 'ранее', 'да', 'этим', 'знаете', 'где', 'он', 'находится', 'о', 'там', 'есть', 'да', 'уже', 'готовы', 'какая', 'площадь', 'вас', 'интересует', 'секунду', 'так', 'ну', 'вот', 'готовая', 'двухкомнатная', 'пятьдесят', 'квадратных', 'метров', 'с', 'отделкой', 'десять', 'миллионов', 'триста', 'да', 'минимум', 'пятнадцать', 'процентов', 'миллион', 'шестьсот', 'продаж', 'дополнительно', 'могу', 'вам', 'отправить', 'скидку', 'два', 'процента', 'она', 'действует', 'в', 'течение', 'двух', 'дней', 'сегодня', 'и', 'завтра', 'удобно', 'сегодня', 'к', 'нам', 'подъехать', 'так', 'ну', 'там', 'договор', 'ээ', 'уже', 'введенный', 'дом', 'поэтому', 'там', 'нужно', 'будет', 'в', 'офисе', 'уточнять', 'а', 'так', 'на', 'этапе', 'строительства', 'там', 'от', 'трех', 'девяти', 'и', 'до', 'четырех', 'восьми', 'но', 'здесь', 'нужно', 'смотреть', 'потому', 'что', 'я', 'тоже', 'готовый', 'дом', 'но', 'там', 'тоже', 'семейная', 'ипотека', 'есть', 'если', 'не', 'семейная', 'то', 'от', 'пяти', 'девяти', 'до', 'шести', 'восьми', 'процентов', 'да', 'вам', 'скидку', 'направлять', 'сегодня', 'ждем', 'вас', 'до', 'девяти', 'офис', 'работает', 'просто', 'этот', 'телефон', 'назовете', 'администратор', 'увидит', 'что', 'вы', 'записаны', 'на', 'встречу', 'да', 'ждем', 'вас', 'тогда', 'угу', 'да', 'конечно', 'намегасы']\n","output_type":"stream"}]},{"cell_type":"code","source":"print(labels[2])","metadata":{"execution":{"iopub.status.busy":"2024-06-15T09:33:46.767429Z","iopub.execute_input":"2024-06-15T09:33:46.767722Z","iopub.status.idle":"2024-06-15T09:33:46.776716Z","shell.execute_reply.started":"2024-06-15T09:33:46.767698Z","shell.execute_reply":"2024-06-15T09:33:46.775845Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-discount', 'B-value', 'I-value', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-discount', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n","output_type":"stream"}]},{"cell_type":"code","source":"print(sentences[3394])","metadata":{"execution":{"iopub.status.busy":"2024-06-15T09:33:46.777722Z","iopub.execute_input":"2024-06-15T09:33:46.777999Z","iopub.status.idle":"2024-06-15T09:33:46.787388Z","shell.execute_reply.started":"2024-06-15T09:33:46.777977Z","shell.execute_reply":"2024-06-15T09:33:46.786571Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"['у', 'тебя', 'сочиняешь', 'которая', 'там', 'ну', 'а', 'как', 'созвониться', 'вечером', 'потому', 'что', 'мне', 'сейчас', 'неудобно', 'разговариватьздравствуйте', 'группа', 'самолет', 'меня', 'зовут', 'NAME', 'как', 'могу', 'по', 'обращаться', 'приятно', 'NAME', 'она', 'себя', 'рассматривает', 'да', 'конечно', 'в', 'котором']\n","output_type":"stream"}]},{"cell_type":"code","source":"print(labels[3394])","metadata":{"execution":{"iopub.status.busy":"2024-06-15T09:33:46.788508Z","iopub.execute_input":"2024-06-15T09:33:46.789110Z","iopub.status.idle":"2024-06-15T09:33:46.798406Z","shell.execute_reply.started":"2024-06-15T09:33:46.789079Z","shell.execute_reply":"2024-06-15T09:33:46.797570Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n","output_type":"stream"}]},{"cell_type":"code","source":"tag_values = target_labels + ['O', 'PAD']\ntag2idx = {t: i for i, t in enumerate(tag_values)}\ntag_values, len(tag_values)","metadata":{"execution":{"iopub.status.busy":"2024-06-15T09:33:46.801726Z","iopub.execute_input":"2024-06-15T09:33:46.802311Z","iopub.status.idle":"2024-06-15T09:33:46.810913Z","shell.execute_reply.started":"2024-06-15T09:33:46.802285Z","shell.execute_reply":"2024-06-15T09:33:46.810094Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"(['B-value', 'I-value', 'B-discount', 'O', 'PAD'], 5)"},"metadata":{}}]},{"cell_type":"code","source":"plt.figure(figsize=(18, 8))\nplt.hist([len(s) for s in sentences], bins=100)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-06-15T09:33:46.811969Z","iopub.execute_input":"2024-06-15T09:33:46.812309Z","iopub.status.idle":"2024-06-15T09:33:47.291461Z","shell.execute_reply.started":"2024-06-15T09:33:46.812275Z","shell.execute_reply":"2024-06-15T09:33:47.290545Z"},"trusted":true},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 1800x800 with 1 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"code","source":"%%time\n# tokenizer = BertTokenizer.from_pretrained(bert_name, do_lower_case = False)\ntokenizer = DebertaV2Tokenizer.from_pretrained(bert_name, do_lower_case = False)","metadata":{"execution":{"iopub.status.busy":"2024-06-15T09:33:47.292689Z","iopub.execute_input":"2024-06-15T09:33:47.293057Z","iopub.status.idle":"2024-06-15T09:33:50.170779Z","shell.execute_reply.started":"2024-06-15T09:33:47.293006Z","shell.execute_reply":"2024-06-15T09:33:50.169769Z"},"trusted":true},"execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d72713e768be48b4a6c33902426f303c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spm.model:   0%|          | 0.00/4.31M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1216a412509f470d9f0f187362875a68"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/579 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"13b1a80c9cfc452cb9326085536b6581"}},"metadata":{}},{"name":"stdout","text":"CPU times: user 1.84 s, sys: 97.3 ms, total: 1.93 s\nWall time: 2.87 s\n","output_type":"stream"}]},{"cell_type":"code","source":"def tokenize_and_preserve_labels(sentence, text_labels):\n    tokenized_sentence = []\n    labels = []\n\n    for word, label in zip(sentence, text_labels):\n\n        # Tokenize the word and count # of subwords the word is broken into\n        tokenized_word = tokenizer.tokenize(word)\n        n_subwords = len(tokenized_word)\n\n        # Add the tokenized word to the final tokenized word list\n        tokenized_sentence.extend(tokenized_word)\n\n        # Add the same label to the new list of labels `n_subwords` times\n        labels.extend([label] * n_subwords)\n\n    return tokenized_sentence, labels","metadata":{"execution":{"iopub.status.busy":"2024-06-15T09:33:50.172069Z","iopub.execute_input":"2024-06-15T09:33:50.172721Z","iopub.status.idle":"2024-06-15T09:33:50.178650Z","shell.execute_reply.started":"2024-06-15T09:33:50.172684Z","shell.execute_reply":"2024-06-15T09:33:50.177635Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"def split_sentence_with_overlap(s_words, s_labels, tokenizer,\n                                max_len=MAX_LEN, overlap=OVERLAP):\n    \"\"\"\n    Разделить предложение на части с перекрытием.\n    :param s_words: предложение -> список слов для разделения\n    :param s_labels: список меток слов\n    :param tokenizer: экземпляр токенизатора\n    :param max_len: максимальная длина части\n    :param overlap: процент перекрытия\n    :return: список частей предложения и список частей меток\n    \"\"\"\n    chunk_size = max_len - 12  # Оставляем место для специальных токенов\n    overlap_size = int(chunk_size * overlap)\n    chunks = []\n    start_index = end_index = 0\n    while end_index < len(s_words):\n        end_index = start_index + chunk_size\n        chunk_words = s_words[start_index:end_index]\n        chunk_text = ' '.join(chunk_words)\n\n        # Токенизируем текст, чтобы убедиться в том, что длина в токенах не превышает max_len\n        tokens = tokenizer.tokenize(chunk_text)\n        while len(tokens) > chunk_size and len(chunk_words):\n            chunk_words = chunk_words[:-1]\n            chunk_text = ' '.join(chunk_words)\n            tokens = tokenizer.tokenize(chunk_text)\n\n        chunks.append((chunk_words,\n                       s_labels[start_index: start_index + len(chunk_words)],\n                       start_index))\n\n        # У нас один чанк и нечего дальше крутить цикл - виснет\n        if len(chunk_words) == len(s_words):\n            break\n\n        # найдем сколько слов входит в перекрытие для вычисления индекса смещения\n        tokens = []\n        overlap_index = 0\n        reversed_words = chunk_words[::-1]\n        # пока длина токенов перекрытия меньше размера перекрытия добавляем по одному слову\n        while len(tokens) < overlap_size:\n            overlap_index += 1\n            tokens = tokenizer.tokenize(' '.join(reversed_words[:overlap_index]))\n\n        end_index = start_index + len(chunk_words)\n        # Следующая часть начинается с учетом перекрытия\n        start_index += len(chunk_words) - overlap_index\n\n    new_words, new_labels = [], []\n    for chunk_words, chunk_labels, start_index in chunks:\n        new_words.append(chunk_words)\n        new_labels.append(chunk_labels)\n\n    return new_words, new_labels\n\n\ndef split_sentences(sentences, labels, row_labels, tokenizer, max_len=MAX_LEN, overlap=OVERLAP):\n    \"\"\"\n    Обработка списка списков предложений и списка списков меток\n    :param sentences: список списков предложений\n    :param labels: список списков меток\n    :param row_labels: список меток предложений (нужно для стратификации)\n    :param tokenizer: экземпляр токенизатора\n    :param max_len: максимальная длина части\n    :param overlap: процент перекрытия\n    :return: новые списки предложений и меток\n    \"\"\"\n    new_sentences, new_labels, new_row_labels, idx_rows = [], [], [], []\n\n    print('Разделение предложений на части:')\n    for idx, (s_words, s_labels, s_row) in tqdm(enumerate(zip(sentences, labels, row_labels)),\n                                                total=len(sentences)):\n        spl_snt, spl_lbl = split_sentence_with_overlap(s_words,\n                                                       s_labels,\n                                                       tokenizer,\n                                                       max_len=max_len,\n                                                       overlap=overlap)\n        new_sentences.extend(spl_snt)\n        new_labels.extend(spl_lbl)\n        new_row_labels.extend([s_row] * len(spl_snt))\n        idx_rows.extend([idx] * len(spl_snt))\n\n    return new_sentences, new_labels, new_row_labels, idx_rows","metadata":{"execution":{"iopub.status.busy":"2024-06-15T09:33:50.180124Z","iopub.execute_input":"2024-06-15T09:33:50.180475Z","iopub.status.idle":"2024-06-15T09:33:50.201151Z","shell.execute_reply.started":"2024-06-15T09:33:50.180440Z","shell.execute_reply":"2024-06-15T09:33:50.200209Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# разделение длинных предложений на части, так чтобы одно предложение не выходило за предел MAX_LEN токенов\n\nprint(f'Количество предложений до: {len(sentences)}\\n')\n\nsentences, labels, row_labels, idx_rows = split_sentences(sentences, labels, row_labels,\n                                                          tokenizer, overlap=0.25)\n\nprint(f'\\nКоличество предложений после: {len(sentences)}')","metadata":{"execution":{"iopub.status.busy":"2024-06-15T09:33:50.202290Z","iopub.execute_input":"2024-06-15T09:33:50.202586Z","iopub.status.idle":"2024-06-15T09:42:21.066737Z","shell.execute_reply.started":"2024-06-15T09:33:50.202550Z","shell.execute_reply":"2024-06-15T09:42:21.065803Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"Количество предложений до: 7900\n\nРазделение предложений на части:\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 7900/7900 [08:30<00:00, 15.47it/s] ","output_type":"stream"},{"name":"stdout","text":"\nКоличество предложений после: 10102\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"tokenized_texts_and_labels = [\n    tokenize_and_preserve_labels(sent, labs)\n    for sent, labs in zip(sentences, labels)\n]","metadata":{"execution":{"iopub.status.busy":"2024-06-15T09:42:21.067946Z","iopub.execute_input":"2024-06-15T09:42:21.068263Z","iopub.status.idle":"2024-06-15T09:42:51.470554Z","shell.execute_reply.started":"2024-06-15T09:42:21.068237Z","shell.execute_reply":"2024-06-15T09:42:51.469663Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"tokenized_texts = [token_label_pair[0] for token_label_pair in tokenized_texts_and_labels]\n\nlabels = [token_label_pair[1] for token_label_pair in tokenized_texts_and_labels]\n\ninput_ids = pad_sequences([tokenizer.convert_tokens_to_ids(txt) for txt in tokenized_texts],\n                          maxlen = MAX_LEN, dtype = \"long\", value = 0.0,\n                          truncating = \"post\", padding = \"post\")\n\ntags = pad_sequences([[tag2idx.get(l) for l in lab] for lab in labels],\n                     maxlen = MAX_LEN, value = tag2idx[\"PAD\"], padding = \"post\",\n                     dtype = \"long\", truncating = \"post\")\n\nattention_masks = [[float(i != 0.0) for i in ii] for ii in input_ids]","metadata":{"execution":{"iopub.status.busy":"2024-06-15T09:42:51.471839Z","iopub.execute_input":"2024-06-15T09:42:51.472212Z","iopub.status.idle":"2024-06-15T09:43:14.252899Z","shell.execute_reply.started":"2024-06-15T09:42:51.472178Z","shell.execute_reply":"2024-06-15T09:43:14.251893Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"def get_model():\n    \n    model = DebertaV2ForTokenClassification.from_pretrained(\n        bert_name,\n        num_labels = len(tag2idx),\n        output_attentions = False,\n        output_hidden_states = False,\n        ignore_mismatched_sizes=True,\n    )\n    \n    model.to(device)\n    \n    FULL_FINETUNING = True\n    if FULL_FINETUNING:\n        param_optimizer = list(model.named_parameters())\n        no_decay = ['bias', 'gamma', 'beta']\n        optimizer_grouped_parameters = [\n            {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n             'weight_decay_rate': 0.01},\n            {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n             'weight_decay_rate': 0.0}\n        ]\n    else:\n        param_optimizer = list(model.classifier.named_parameters())\n        optimizer_grouped_parameters = [{\"params\": [p for n, p in param_optimizer]}]\n\n    optimizer = AdamW(\n        optimizer_grouped_parameters,\n        lr=3e-5,\n        eps=1e-8\n    )    \n    \n    return model, optimizer","metadata":{"execution":{"iopub.status.busy":"2024-06-15T09:43:14.254151Z","iopub.execute_input":"2024-06-15T09:43:14.254451Z","iopub.status.idle":"2024-06-15T09:43:14.262813Z","shell.execute_reply.started":"2024-06-15T09:43:14.254427Z","shell.execute_reply":"2024-06-15T09:43:14.261960Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"def train_model(name_model, best_score_total=0):\n    \n    epochs = 30\n    max_grad_norm = 1.0\n\n    # Total number of training steps is number of batches * number of epochs.\n    total_steps = len(train_dataloader) * epochs\n\n    # Create the learning rate scheduler.\n    scheduler = get_linear_schedule_with_warmup(\n        optimizer,\n        num_warmup_steps = 0,\n        num_training_steps = total_steps\n    )\n    ## Store the average loss after each epoch so we can plot them.\n    loss_values, validation_loss_values = [], []\n    best_score = 0\n    not_increase = 0\n    not_increase_stop = 5\n\n    #for _ in trange(epochs, desc = \"Epoch\"):\n    for epoch in range(epochs):\n        # ========================================\n        #               Training\n        # ========================================\n        # Perform one full pass over the training set.\n\n        # Put the model into training mode.\n        model.train()\n        # Reset the total loss for this epoch.\n        total_loss = 0\n\n        # Training loop\n        for step, batch in tqdm(enumerate(train_dataloader), total=len(train_dataloader)):\n            # Перенос батча на GPU\n            batch = tuple(t.to(device) for t in batch)\n            b_input_ids, b_input_mask, b_labels = batch\n\n            # Убедитесь, что метки имеют тип LongTensor\n            b_labels = b_labels.long()\n\n            # Всегда очищайте любые ранее рассчитанные градиенты перед выполнением обратного прохода\n            model.zero_grad()\n\n            # Прямой проход\n            outputs = model(\n                b_input_ids, \n                token_type_ids=None,\n                attention_mask=b_input_mask, \n                labels=b_labels\n            )\n\n            # Получение потерь\n            loss = outputs[0]\n            # Выполнение обратного прохода для расчета градиентов\n            loss.backward()\n            # Отслеживание тренировочных потерь\n            total_loss += loss.item()\n            # Ограничение нормы градиента\n            torch.nn.utils.clip_grad_norm_(parameters=model.parameters(), max_norm=max_grad_norm)\n            # Обновление параметров\n            optimizer.step()\n            # Обновление скорости обучения\n            scheduler.step()\n\n            \n\n        # Calculate the average loss over the training data.\n        avg_train_loss = total_loss / len(train_dataloader)\n        #print(\"Average train loss: {}\".format(avg_train_loss))\n\n        # Store the loss value for plotting the learning curve.\n        loss_values.append(avg_train_loss)\n    \n        # ========================================\n        #               Validation\n        # ========================================\n        # After the completion of each training epoch, measure our performance on\n        # our validation set.\n\n        # Put the model into evaluation mode\n        model.eval()\n        # Reset the validation loss for this epoch.\n        eval_loss, eval_accuracy = 0, 0\n        nb_eval_steps, nb_eval_examples = 0, 0\n        predictions , true_labels = [], []\n        for batch in tqdm(valid_dataloader):\n            batch = tuple(t.to(device) for t in batch)\n            b_input_ids, b_input_mask, b_labels = batch\n\n            # Telling the model not to compute or store gradients,\n            # saving memory and speeding up validation\n            with torch.no_grad():\n                # Forward pass, calculate logit predictions.\n                # This will return the logits rather than the loss because we have not provided labels.\n                outputs = model(\n                    b_input_ids, \n                    token_type_ids = None,\n                    attention_mask = b_input_mask, \n                    labels = b_labels\n                )\n            # Move logits and labels to CPU\n            logits = outputs[1].detach().cpu().numpy()\n            label_ids = b_labels.to('cpu').numpy()\n\n            # Calculate the accuracy for this batch of test sentences.\n            eval_loss += outputs[0].mean().item()\n            predictions.extend([list(p) for p in np.argmax(logits, axis = 2)])\n            true_labels.extend(label_ids)\n\n        eval_loss = eval_loss / len(valid_dataloader)\n        validation_loss_values.append(eval_loss)\n    \n        #print(\"Validation loss: {}\".format(eval_loss))\n        pred_tags = [tag_values[p_i] for p, l in zip(predictions, true_labels)\n                                     for p_i, l_i in zip(p, l) if tag_values[l_i] != \"PAD\"]\n        valid_tags = [tag_values[l_i] for l in true_labels\n                                      for l_i in l if tag_values[l_i] != \"PAD\"]\n        score_val = f1_score(\n                valid_tags, pred_tags, \n                labels = ['B-value', 'I-value', 'B-discount', 'O'], \n                average = 'macro'\n        )\n        #print(\"Validation Accuracy: {}\".format(accuracy_score(pred_tags, valid_tags)))\n        #print(\"Validation F1-Score: {}\".format(score_val))\n        if best_score < score_val:\n            best_score = score_val         \n            not_increase = 0         \n            if best_score_total < best_score:\n                best_score_total = best_score\n                msg = f'save model, {best_score_total}, {score_val}'\n                print(epoch, msg)\n                \n                # Save the fine-tuned model locally\n                model.save_pretrained(f\"./results/checkpoint-last\")\n                \n                try:\n                    Path(name_model).mkdir(parents = True, exist_ok = True)\n                    model.save_pretrained(name_model)\n                except:    \n                    pass\n            else:\n                msg = f'... {best_score_total}, {score_val}'\n                print(epoch, msg)\n        else:\n            not_increase += 1\n            msg = f'not_increase = {not_increase}, {best_score}, {score_val}'\n            print('epoch:', epoch, msg)\n            if not_increase >= not_increase_stop:                \n                print('not_increase = ', not_increase_stop)\n                break\n                \n    return best_score_total","metadata":{"execution":{"iopub.status.busy":"2024-06-15T09:43:14.264139Z","iopub.execute_input":"2024-06-15T09:43:14.264446Z","iopub.status.idle":"2024-06-15T09:43:14.320920Z","shell.execute_reply.started":"2024-06-15T09:43:14.264423Z","shell.execute_reply":"2024-06-15T09:43:14.319894Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"SEEDS = 1\nscores = []\nbatch_size = 4\n\nbest_score = 0 \n\nfolds = 5\n\nfor seed in (17,):    \n    # kf = KFold(n_splits = 5, random_state = seed, shuffle = True)\n    kf = StratifiedKFold(n_splits=folds, random_state=seed, shuffle=True)\n    for fold, (train_index, val_index) in enumerate(kf.split(input_ids, row_labels)):\n        \n        test_index = sorted(set([idx_rows[i] for i in val_index]))\n        df.iloc[test_index].to_csv(f'test_fold_{fold}.csv', index=False)\n        \n        clear_output(wait = False)\n        print('SEEDS:', seed, 'Fold:', fold)\n        print(np.mean(scores) - np.std(scores))\n        \n        tr_inputs  = input_ids[train_index]\n        val_inputs = input_ids[val_index]\n        \n        tr_tags  = tags[train_index]\n        val_tags = tags[val_index]\n        \n        tr_masks  = np.array(attention_masks)[train_index]\n        val_masks = np.array(attention_masks)[val_index]\n        \n        tr_inputs = torch.tensor(tr_inputs)\n        val_inputs = torch.tensor(val_inputs)\n\n        tr_tags = torch.tensor(tr_tags, dtype=torch.long)\n        val_tags = torch.tensor(val_tags, dtype=torch.long)\n\n        tr_masks = torch.tensor(tr_masks)\n        val_masks = torch.tensor(val_masks)\n        \n        train_data = TensorDataset(tr_inputs, tr_masks, tr_tags)\n        train_sampler = RandomSampler(train_data)\n        train_dataloader = DataLoader(train_data, sampler = train_sampler, batch_size = batch_size)\n        \n        valid_data = TensorDataset(val_inputs, val_masks, val_tags)\n        valid_sampler = SequentialSampler(valid_data)\n        valid_dataloader = DataLoader(valid_data, sampler = valid_sampler, batch_size = batch_size)\n        \n        model, optimizer = get_model()\n        \n        name_model = f'./best_model-{fold}-{folds}'\n        score = train_model(name_model, best_score)\n        scores.append(score)   \n        best_score = score   \n               \n        del model, optimizer; gc.collect()     \n        \n        # хватит одного фолда\n        break        \n        \nprint(np.mean(scores) - np.std(scores))","metadata":{"execution":{"iopub.status.busy":"2024-06-15T09:43:14.322422Z","iopub.execute_input":"2024-06-15T09:43:14.322888Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Fold 0\nnan\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/1.33G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"105aa96293cb45459d1ec4210e25bff9"}},"metadata":{}},{"name":"stderr","text":"Some weights of DebertaV2ForTokenClassification were not initialized from the model checkpoint at microsoft/mdeberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n100%|██████████| 2165/2165 [13:07<00:00,  2.75it/s]\n100%|██████████| 361/361 [00:39<00:00,  9.17it/s]\n","output_type":"stream"},{"name":"stdout","text":"0 save model, 0.9307123293214201, 0.9307123293214201\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 2165/2165 [13:07<00:00,  2.75it/s]\n100%|██████████| 361/361 [00:39<00:00,  9.18it/s]\n","output_type":"stream"},{"name":"stdout","text":"1 save model, 0.9523516416315905, 0.9523516416315905\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 2165/2165 [13:07<00:00,  2.75it/s]\n100%|██████████| 361/361 [00:39<00:00,  9.18it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch: 2 not_increase = 1, 0.9523516416315905, 0.9509763219468501\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 2165/2165 [13:07<00:00,  2.75it/s]\n100%|██████████| 361/361 [00:39<00:00,  9.18it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch: 3 not_increase = 2, 0.9523516416315905, 0.9479347470500556\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 2165/2165 [13:07<00:00,  2.75it/s]\n100%|██████████| 361/361 [00:39<00:00,  9.18it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch: 4 not_increase = 3, 0.9523516416315905, 0.949241977350369\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 2165/2165 [13:07<00:00,  2.75it/s]\n100%|██████████| 361/361 [00:39<00:00,  9.17it/s]\n","output_type":"stream"},{"name":"stdout","text":"5 save model, 0.9546044428046511, 0.9546044428046511\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 2165/2165 [13:07<00:00,  2.75it/s]\n100%|██████████| 361/361 [00:39<00:00,  9.18it/s]\n","output_type":"stream"},{"name":"stdout","text":"epoch: 6 not_increase = 1, 0.9546044428046511, 0.9514314616527293\n","output_type":"stream"},{"name":"stderr","text":" 49%|████▉     | 1057/2165 [06:24<06:43,  2.75it/s]","output_type":"stream"}]},{"cell_type":"code","source":"from IPython.display import display, FileLink\nfrom zipfile import ZipFile, ZIP_DEFLATED as ZD\nfrom glob import glob\n\nfiles = glob(f'results/checkpoint-last/*.*') + glob('*.csv')\nzip_filename = f'model_mdeberta_{train_version}.zip'\nwith ZipFile(zip_filename, 'w',  compression=ZD, compresslevel=9) as zip_file:\n    for filename in files:\n        print(filename)\n        zip_file.write(filename)\nFileLink(zip_filename)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}